# JLpeg: Pattern Matching and Parsing For Julia

```@meta
CurrentModule = JLpeg
DocTestSetup = quote
    using JLpeg
    import JLpeg.Combinators: *, -, %, |, ^, ~, !, >>, >:, inv
end
```

JLpeg provides a fast [Parsing Expression
Grammar](https://en.wikipedia.org/wiki/Parsing_expression_grammar) engine for
matching patterns in strings, using a bytecode virtual machine based on the
pioneering work of [Roberto
Ierusalimschy](https://www.inf.puc-rio.br/~roberto/docs/peg.pdf).

Compared to regular expressions, PEGs offer greater power and expressivity.  They
match a superset of regex patterns, while formalizing and extending the deviations
from regular languages offered by production regex engines such as PCRE.  PEGs are
able to parse recursive rule patterns, employ lookahead and lookbehind predicates,
and avoid the sort of worst-case complexity the regex is prone to, for most useful
patterns.

Compared with parser combinators, a more common algorithm for matching PEG grammars,
the approach taken by this package is superior.  A bytecode interpreter allows
several key optimizations which parser combinators do not in practice employ.
Generally such libraries choose between a naive backtracking algorithm with bad time
complexity, and a memorizing packrat algorithm which trades this for bad space
complexity, with consequent memory pressure.  Critically, a `JLpeg` pattern of the
form `a ← "b" / . a` becomes a loop, rather than consuming the program stack.  JLpeg
generates programs which may be inspected and modified, and uses an innovative
thrown-label pattern to allow excellent error reporting and recovery.

Compared with a "compiler compiler" such as ANTLR or the classic yacc/bison, `JLpeg`
does not generate source code, but rather bytecode, which Julia is able to JIT into
near-optimal machine code on the fly.  These systems require an imput stream to be
reduced to tokens, an abstraction PEGs do not need, which allows `JLpeg` to parse
contextually-valid grammars which cannot be readily tokenized.  PEGs are also far
more suitable for scanning, captures, and other pattern-recognition tasks than these
programs, which are only well-suited to parsing of full grammars, a task `JLpeg` also
excels at.

## Patterns

Parsing Expression Grammars are built out of patterns. These begin with atomic units
of recognition, and are combined into complex rules, which can call other rules,
recursively, thereby recognizing context free, and some context sensitive, languages.
LPeg, JLpeg's inspiration, uses a
[SNOBOL](https://en.wikipedia.org/wiki/SNOBOL)-style set of operator overloads as the
basic tool for building up patterns, a practice we also follow.

Patterns and their combination are the building block of JLpeg recognition engines.
They are immutable and may be freely recombined and reused, unlike either regular
expressions or the parsers generated by typical compiler-compilers.

The API of JLpeg hews closely to [LPeg](http://www.inf.puc-rio.br/~roberto/lpeg/),
with several extensions, refinements, and a more natively Julian character.

## Combination

The basic operations are as follows:

| Operator                | Description                                                 |
|-------------------------|:------------------------------------------------------------|
| `P(string::String)`     | match a literal String `string`                             |
| `P(n::UInt)`            | match any `n` characters                                    |
| `P(-n)`                 | match if there are at least `n` characters remaining        |
| `P(sym::Symbol)`        | match the rule named `:sym`                                 |
| `S(s::String)`          | match the `S`et of all characters in `string`               |
| `R("xy")`, `R('x','y')` | matches any character between `x` and `y` (`R`ange)         |
| `B(patt)`               | match `patt` behind the cursor, without advancing           |
| `patt^n`                | match at least `n` repetitions of `patt`                    |
| `patt^-n`               | match at most `n` repetitions of `patt`                     |
| `patt^[n:m]`            | match between `n` and `m` repetitions of `patt`             |
| `patt^[n]`              | match exactly `n` repetitions of `patt`                     |
| `patt1 * patt2`         | match the sequence `patt1` , `patt2`                        |
| `patt1 \| patt2`        | match `patt1` or `patt2`, in that order                     |
| `patt1 - patt2`         | match `patt1` if `patt2` does not match                     |
| `!patt`, `¬patt`        | negative lookahead, succeeds if `patt` fails                |
| `~patt`                 | lookahead, match `patt` without advancing                   |
| `patt1 >> patt2`        | match `patt1`, then search the string for the next `patt2`. |
| `P(true)`, `ε`          | always succeed                                              |
| `P(false)`, `∅`         | always fail                                                 |

In keeping with the spirit of LPeg, `P"string"` is equivalent to `P("string")`, and
this is true for `S` and `R` as well.  These basic operations are not recursive, and
without further modification will match to the longest substring recognized by the
pattern.  This is sufficient to match all regular languages.

### A Note About Piracy

You will note that combining Patterns involves a great deal of operator overloading.
In Julian circles, operators are presumed to have [a certain contract](@extref
`Avoid-type-piracy`), although this is informal and has a certain latitude.  Some of
our operators comply with this expectation: `*` and `^` are used for concatenation
and repetition for `AbstractString`s, as they are with `Pattern`s, although the
meaning of repetition is broader for patterns.  Others do not: particularly egregious
is `!`, which is expected to always return a [`Bool`](@extref `Core.Bool`), and `>:`
(an [`Action`](#Actions)), which has no relationship to supertypes whatsoever.  `|`
and `-` are justifiable, in my opinion: `|` is firmly grounded in tradition and `a |
b` would be pronounced "a or b", while subtraction has a huge variety of meanings in
mathematics; our use, as one should expect, is neither commutative nor associative.
`~` and `>>` bear little resemblance to their ordinary meanings.

Broadly speaking, the combinator operators in JLpeg are a combination of
availability, operator precedence, and mnemnonic weight, in that order.  For example,
`&patt` is the signifier for lookahead in the PEG definition, we use `~` because it's
unary, and Julia has but few unary operators.

In any case, we shadow operators, rather than overloading the ones found in `Base`,
and they aren't exported.  We provide [`JLpeg.Combinators`](@ref) as an easy way to
bring them into scope if desired.  Most users will stick to the [`@rule`](@ref) and
[`@grammar`](@ref) macros, which don't require bringing operators into scope.

## Matching

[`match`](@ref)`(pattern::`[`Pattern`](@ref), `string`::[AbstractString](@extref
`Core.AbstractString`)) will attempt to match the pattern against the string,
returning a [`PegMatch`](@ref) `<:` [AbstractMatch](@extref `Base.RegexMatch`). In
the event of a failure, it returns a [`PegFail`](@ref), with the index of the failure
at `.errpos`.  Note that unlike regular expressions, JLpeg will not skip ahead to
find a pattern in a string, unless the pattern is so constructed.  We offer the
shorthand `"" >> patt`, the "fast-forward" operator, to convert a pattern into its
searching equivalent.  `P""` matches the empty string, and JLPeg will convert Strings
and Integers (but not Bools) into patterns when able.

```jldoctest
julia> match(P"123", "123456")
PegMatch(["123"])

julia> match(P"abc" * "123", "abc123")
PegMatch(["abc123"])

julia> match(P"abc" | "123", "123")
PegMatch(["123"])

julia> match(P"abc"^1, "abcabcabc")
PegMatch(["abcabcabc"])

julia> match((!S"123" * R"09")^1, "0987654321")
PegMatch(["0987654"])

julia> match("" >> P"5", "0987654321")
PegMatch(["098765"])

julia> match(~P"abc", "abc123")
PegMatch([""])

julia> match(~P"abc", "123abc") # fails
PegFail("123abc", 1)
```

The operators introduce a pattern 'context', where any `a <op> b` combination where
`a` or `b` is a Pattern will attempt to cast the other argument to a Pattern when
appropriate.  Generally, a `MethodError` may be repaired by using `P` on the left
side of the the operator, although we can't guarantee that other method overloads for
those operators might apply.  Notably, `*` is used for concatenation of strings,
although in the JLpeg context, `P"abc" * P"123"` is in fact the same as `P("abc" *
"123")`.

This UI is adequate for light work, but the [macros](#Rules-and-Grammars) discussed
later are cleaner to work with, defined such that `P` should never be necessary,
although any of the public names in the [`JLpeg`](reference.md) module may be used,
and needn't be imported into your package to do so.

Note that, unlike regular expressions, PEG matching always starts with the first
character.  Any match returned by a call to `match(patt, string)` will therefore be a
prefix of the string, up to and including the entire string.

Most interesting uses of pattern recognition will call for more than matching the
longest substring.  For those more complex cases, we have [`Captures`](#Captures) and
[`Actions`](#Actions).

### Rules and Grammars

While simple patterns may be composed by assigning to variables and using those
variable names to build up more complex patterns, this doesn't allow for recursion,
which is essential for matching many strings of interest, perhaps most.

For this purpose, we have rules, which are simply named patterns.  A rule with no
references to another rule within it may be used for matching directly, while those
with such references (including a reference to itself) must be composed into
grammars.

As is the PEG convention, a rule reduction uses the left arrow `←`, which you can
type as `\leftarrow` (or in fact `\lefta[TAB]`), also defined as `<--`.  A simple
grammar can look like this:

```jldoctest; output=false
abc_and = :a <-- P"abc" * (:b | P"")
_123s   = :b ← P"123"^1 * :a
abc123  = Grammar(abc_and, _123s)

match(abc123, "abc123123123abc123abc")
# output
PegMatch(["abc123123123abc123abc"])
```

Although we suggest as a matter of style that a grammar use one arrow form or the
other, with `←` preferred.

The first rule is the start rule, which must succeed if the match is to succeed.  A
grammar which is missing rules will throw a [`PegError`](@ref), but duplicate rules
are undefined behavior.  Currently JLpeg will compile the last rule of that name it
encounters, but this behavior must not be relied upon.

The preferred way to create rules and grammars is with the macros [`@rule`](@ref) and
[`@grammar`](@ref), which avoid the tedium of decorating expressions with [`P`](@ref)
entirely.  Any [`Integer`](@extref `Core.Integer`), [`String`](@extref
`manual/strings`), [`Symbol`](@extref `Symbols`), or [`Char`](@extref
`man-characters`), found on its own, is converted into the pattern equivalent.  While
this is not true of booleans, an idiomatic way to spell `true` and `false` in JLpeg
is `""` and `S""` respectively (read: "the empty string" and "the empty set").  These
are compiled into the same code as `P(true)` and `P(false)`.  JLpeg also defines, but
does not export, `ε` for `P(true)` and `∅` for `P(false)`, and these may be used in
grammars and rules as well, with `\varepsilon` (`\vare[TAB]`) and `\emptyset`
(`\emp[TAB]`) respectively.

Public variable names from `JLpeg` will always refer to the values they have in the
module.  Any other variable will be escaped, so it will have the expected meaning.

To give an example, this rule:

```julia
@rule :a ← "foo" *  [S"123" | "abc"^0]^1
```

Is equivalent to this expression:

```julia
a = :a ← P("foo") * Cg(S("123") | P("abc")^0)^1
```

Although the definitions of the operators and string macros would allow this reduction:

```julia
a = :a ← P"foo" * Cg(S"123" | "abc"^0)^1
```

Which is a bit less cumbersome (we try).  Note that the `@rule` form doesn't require
the importation of `@S_str`, or any other exported name, thanks to the nature of
Julia macros.  You may always use any form of a pattern in `@rule` or `@grammar`, all
of these are equivalent: `P("string")`, `P"string"`, and `"string"`.

#### A Sample Grammar

A classic example of a task forever beyond the reach of regular expressions is balancing parentheses, with JLpeg this is easy:

```@repl
using JLpeg # hide
@grammar parens begin
    :par ← :s * !1
    :s ← (:b | (!S"()" * 1))^1
    :b ← '(' * :s * ')'
end;

match(parens, "(these (must) balance)")

match(parens, "these (must) balance)")

match(parens, "(these (must) balance")

match(parens, "(these (must) balance))")

match(parens, "(these (must))) balance)")
```

`!1` is our equivalent of `$` in regex, a pattern which only succeeds at the end of
input. `1` will match a single Unicode codepoint, and `!` is negative lookahead.

The `@grammar` macro doesn't define variable names for the rules, only the grammar
name given before the expression block.  The first rule is always the start rule.  As
the example shows, it doesn't necessarily match the variable name, although of course
it may.

## Captures

A [`PegMatch`](@ref) defaults to the longest [`SubString`](@extref `Base.SubString`)
when no captures are provided, or when the pattern succeeds but all captures within
fail.  To capture only the substring(s) of interest, use `C(patt)` or just make a tuple
`(patt,)`.

```jldoctest
julia> match("" >> (P"56",), "1234567")
PegMatch(["56"])
```

This matches the empty string, fast-forwards to the first 56, and captures it.  Note
that the pattern is `(P"56",)`, a tuple, not a group; this is syntax sugar for
`P("") >> C(P("56"))`.  The capture can receive a key, which may be either a
Symbol or a String: `(P"56", :fiftysix)` or `(P"56", "fifty six")`.

| [❓]  | Operation               | What it produces                                       |
|------|:------------------------|:-------------------------------------------------------|
| [✅]  | `C(patt [, key])`,      | captures the substring of `patt`                       |
| [✅]  | `(patt,)`               | same as above, note the comma!                         |
| [✅]  | `(patt, key)`           | `key` may be `:symbol` or `"string"`                   |
| [✅]  | `Cg(patt [, key])`,     | captures a Vector of values produced by `patt`,        |
| [✅]  | `[patt], [patt, key]`   | optionally tagged with `key`                           |
| [✅]  | `Cp()`                  | captures `""` so `PegMatch.offsets` has the position   |
| [🔶] | `Cc(any)`                | places `any` in `.captures` at the current offset      |
| [✅]  | `Cr(patt [, key])`      | Range of indices [start:end] of `patt`, optional `key` |

Some more examples:

```jldoctest
julia> @rule :cap123 ← [((S"123"^1,) | R"az"^1)^1];

julia> match(cap123, "abc123zyz123def")
PegMatch([["123", "123"]])

julia> @rule :cap_pos ← [((S"123"^1,) | R"az"^1 * Cp())^1];

julia> match(cap_pos, "abc123zyz123def")
PegMatch([[4, "123", 10, "123", 16]])

julia> @rule :capABC ← [((S"ABC"^1,) | R"az"^1)^1, :capABC];

julia> match(capABC, "abcBCAzyzCCCdef")
PegMatch([:capABC => ["BCA", "CCC"]])
```

The form in `:capABC`, where the rule is grouped as a capture and given a symbol
which is the same as the rule name, is extremely common and gets its own shorthand:

```jldoctest
julia> @rule :capABC <--> ((S"ABC"^1,) | R"az"^1)^1;

julia> match(capABC, "abcBCAzyzCCCdef")
PegMatch([:capABC => ["BCA", "CCC"]])
```

With both `⟷` and `↔︎` as synonyms, these are `\longleftrightarrow` and
`\:left_right_arrow:` respectively.

## Actions

A pattern may be modified with an action to be taken, either at runtime, or, more
commonly, once the match has completed.  These actions are supplied with all captures
in `patt`, or the substring matched by `patt` itself if `patt` contains no captures
of its own.

| [❓]  | Action               | Consequence                                       |
|------|-----------------------|:--------------------------------------------------|
| [✅] | `A(patt, λ)`,         | the returned value of `λ`, as applied             |
| [✅] | `patt <\| λ`          | to the captures in `patt`                         |
| [⭕️] | `Anow(patt, λ)`,      | captures `λ(C(patt)...)` at match time,           |
| [⭕️] | `patt >: λ`           | return `nothing` to fail the match                |
| [✅] | `M(patt, :label)`     | `M`ark a the region of `patt` for later reference |
| [✅️] | `K(patt, :label, op)` | chec`K` `patt` against the last mark with `op`    |
| [✅] | `T(:label)`,          | fail the match and throw `:label`                 |
| [✅] | `patt % :label`       | shorthand for `patt \| T(:label)`                 |

The use of `<|` is meant to be mnemonic of [`|>`](@extref
`Function-composition-and-piping`) for ordinary piping (and shares its
usefully low precedence), without pirating the meaning of the pipe operator.  This way
`patt |> λ` will do the expected thing, `λ(patt)`.

### Marks and Checks

Validation and parsing of strings frequently requires comparison between two
substrings.  For our example, let's consider this toy XML tag grammar.

```@setup toyXML
using JLpeg
```

```@repl toyXML
@grammar xmltag begin
    :doc ← :tags * !1
    :tags ← :opentag * :tags^0 * :closetag
    :opentag ← "<" * R"az"^1 * ">"
    :closetag ← "</" * R"az"^1 * ">"
end;

match(xmltag, "<a><b></b></a>")

match(xmltag, "<a><b></b>")
```

So far so good! We've got a nice recursive tag matcher, without [summoning Zalgo](https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454).  One problem though: it allows any close tag to match any open tag.

```@repl toyXML
match(xmltag, "<a><b></a></b>")
```

To solve this, we have the mark and check mechanism. Let's rewrite the grammar to use them.

```@repl toyXML
@grammar xmltag begin
    :doc ← :tags * !1
    :tags ← :opentag * :tags^0 * :closetag
    :opentag ← "<" * M(R"az"^1, :tag) * ">"
    :closetag ← "</" * K(R"az"^1, :tag) * ">"
end;

match(xmltag, "<a><b></a></b>")

match(xmltag, "<a><b></b></a>")
```

That's more like it!  This mechanism allows for a fully declarative PEG grammar which
matches valid XML.  It's also applicable to Python-style indentation, Lua's long
strings, and much more.

`K` has a two-argument form (shown), where the check confirms that the two substrings
are identical.  In the three-argument form, a function may be provided, which must
have the signature `(marked::AbstractString, checked::AbstractString)::Bool`, with
the result of calling the function on the regions of interest used to pass or fail
the match.  This may also be written in [do syntax](@extref
`Do-Block-Syntax-for-Function-Arguments`).

For the most common comparisons, `JLpeg` provides several built-ins, which may be
invoked by providing these symbols as the third argument.  These don't have to
allocate SubStrings or look up a function, and should always be preferred for what
they do.

| Built-in  |           Match when           |
| :-------- | :----------------------------- |
| `:(==)`   | Regions are identical          |
| `:length` | Regions have the same length   |
| `:close`  | There is a mark with this tag  |
| `:always` | Whether the mark exists or not |
| `:gt`     | length(r2) > length(r1)        |
| `:lt`     | length(r2) < length(r1)        |
| `:gte`    | length(r2) ≥ length(r1)        |
| `:lte`    | length(r2) ≤ length(r1)        |

The builtin `:(==)` is the default used in the two-argument form of [`K`](@ref).  The
length comparisons in the table may look backward, but is easy to remember in
practice: `K(patt, :tag, :gt)` means "this is greater than that", and so on.  These
are abbreviations and not symbols, because, for one example, `K(patt, :tag, >)` is a
perfectly valid check, but will use lexicographic comparison (as always with strings
and `>`), not length comparison.  `:(==)` is identical in meaning to `==` in this
context, but may be safely elided.

With the exception of `:always`, a check will fail if there is no mark with the same
key.  This includes user-provided functions, which won't trigger if a mark isn't
found. All checks, _including_ `:always`, are only performed if the enclosed pattern
succeeds.

Marks and checks are independent of the capture mechanism, but since the regions of
interest are frequently worth capturing, we provide [`CM(patt, :sym)`](@ref CM) as a
shorthand for `C(M(patt, :sym), :sym)`, and [`CK(patt, :sym, check)`](@ref CK) as
shorthand for `C(K(patt, :sym, check), :sym)`.

#### Checks and Predicates

Successful checks will remove the corresponding mark, unless they're inside
predicates, `~` or `!`.  The "exception to the exception" is `:always`, which, given
the semantics of the name, and the fact that it exists entirely to remove marks, we
felt should do what it says on the label.

This differing behavior inside predicates is the better semantic, since it allows
lookahead for a checked-mark which is later consumed.

To illustrate, we'll show a grammar for [Lua's long
strings](https://www.inf.puc-rio.br/~roberto/lpeg/lpeg.html#ex).  This illustrates
the motive both for our choice of check behavior inside predicates, and the motive
for JLpeg's innovative mark and check mechanism. LPeg can provide equivalent
functionality for many cases, using a more general but somewhat cumbersome mechanism.

```@setup longstring
using JLpeg #hide
```

```@repl longstring
@grammar longstr begin
    :str ← :open * :body * :close
    :open ← '[' * M("="^0, :equals) * '['
    :body ← ((!:close * 1)^0, :string)
    :close ← ']' * K("="^0, :equals) * ']'
end;

match(longstr, "[[]]")

match(longstr, "[[long strings ]]")

match(longstr, "[==[end with a ]=] token]==]")

match(longstr, "[==[the equals must balance]=]")
```

Lua's long strings are a nice bit of syntax, because they have the enclosure
property: it is always possible to turn a literal string into a program string, no
matter the contents, because the equals signs in e.g. `[===[` must be matched with
`]===]`.  I wish Julia had a string syntax which functions the same way.

We see that the `:body` rule contains `(!:close * 1)^0`, a pattern which experienced
PEG users recognize instantly as matching zero or more characters provided that
lookahead doesn't match the `:close` rule.

Because the negative-lookahead `:close` always matches the `:close` rule first on the
closing region, if `K` didn't behave differently inside predicates, this would
consume the mark, so the `:close` in the `:str` rule would always fail.

Small note: a rule like this should use the `:length` builtin, since the pattern
matching has already guaranteed that if the lengths are equal the contents will be
identical, so this form does extra work.  The two-argument form was chosen for
pedagogical reasons.

#### Limitation and Performance

Marks and checks come with an **important limitation**: they must not contain other
marks and checks.  Any other pattern is ok, including captures and all other actions.
A future version of JLpeg may check for this condition and refuse to compile, the
current behavior will silently corrupt your parse.  The author's opinion is that this
is no limitation in practice, after all, one might match the longer region and
perform whatever inner checks are desired.  If you find yourself with a real-world
grammar which would benefit from nested marks, feel free to open an issue, and we can
decide if the complexity, performance impact, and unclear semantics (does an inner
mark come before, or after, its enclosing mark?) is worth it.

Note that marks are only removed once a corresponding check succeeds, and grammars or
strings which don't close their marks will leave them on the stack.  This is normally
harmless, the worst that can come of it is JLpeg throwing an `InexactError` once
there are more than `typemax(UInt16)` marks on the stack, but it's certainly possible
to create bad performance.  For example, by stacking up a bunch of mark `:a` while
checking for mark `:b`, every check will be forced to fruitlessly look for the
nonexistent mark on a growing stack of marks.  It takes some real effort to produce a
grammar which will do this, however.

If you have a grammar where some paired regions may be implicitly closed, you can use
`K(patt, :tag, :always)` to close the mark by fiat; this check succeeds whether the
mark exists or not.  If you want the check to fail if the mark doesn't exist, use
`K(patt, :tag, :close)` instead.  This comes up in Markdown parsing, where, for
example, `**` for emphasis is allowed to end when the paragraph ends, without needing
to be closed.

Final note: this thorough discussion might leave some with the impression that marks
and checks aren't performant, are tricky, to be avoided in practice, etc.  Fear not!
Typical uses will consume marks nearly as fast as they're generated, and it's rare
for marks to overlap, that is, normally the check will be compared against the latest
mark.  To cite our XML example, the mark stack will be as deep as the tags are
nested, comparisons are always against the top mark, and any mismatch fails the
entire parse. This has the same time complexity as a grammar which allows mismatched
tags, with a tiny added constant factor which is well-used.

Practical use of mark and check is as fast as it reasonably can be, and enables
recognition of many common patterns in strings.

### Throws and Recovery

The greatest challenge for good parsing has always been error reporting and recovery.
With old-school [lex and yacc](https://www.wikiwand.com/en/Yacc), the conventional
wisdom was to develop the grammar for a language or DSL using the compiler-compiler
toolkit, to assure that the grammar is actually in a useful context-free class, then
handroll a recursive-descent parser for production use, in order to provide users
with useful error messages when they inevitably create syntax errors.

[`JLpeg`](index.md), being a PEG parser, is a formalization of the classic
recursive-descent parsing strategy.  It includes a mechanism pioneered by
[lpeglabel](https://github.com/sqmedeiros/lpeglabel), modestly improved in our
implementation, which allows a pattern to throw a specific error when an expected
aspect of parsing is violated.

`T(:label)` fails the match, records the position of that failure, and throws
`:label`.  If there is a rule by that name, it is attempted for error recovery,
otherwise `:label` and the error position are attached to the `PegFail` struct, in
the event that the whole pattern fails.  The label `:default` is reserved by JLpeg
for reporting failure of patterns which didn't otherwise throw a label.

Consider a simplified pattern for matching single-quoted strings:

```@setup badstring
using JLpeg #hide
```

```@repl badstring
@rule :string ← "'" * (!"'" * 1)^0 * "'";

match(string, "'a string'")

match(string, "'not a string")
```

We do mark the point of failure, which is better than average; a normal PEG or parser
combinator will silently fail to match, without informing the user of where. But we
can do better with throws.

```@repl badstring
@rule :string  ←  "'" * (!"'" * 1)^0 * ("'" % :badstring)

match(string, "'not a string")
```

This provides us both with the point of failure, and the cause, data which can be
used to provide a helpful error message to the user.

A Throw with a matching rule will attempt that rule on throw, if this succeeds, the
parse continues.  This can be used to embed errors while continuing to check the
validity of the grammar, as in this example.

```@repl badstring
@grammar strmatch begin
    :strings ← " "^0 * "'" * (!S"'\n'" * 1)^0 * ("'" % :missedend) * :strings^0 * !1
    :missedend ← ("\n", :str_newline_error)
end;

match(strmatch, "'a string' 'another string'")

match(strmatch, "'a string\n 'another string'")

match(strmatch, "'a string' 'another string")
```

Here we have a grammar matching at least one single-quoted string, which may not
contain a literal newline. If we fail to match a string, the `:missedend` rule looks
for a newline, which it captures and tags, enabling the parse to continue.
Subsequent code can look for `:str_newline_error`, or any number of such
error-signalling keys.  Since a [`SubString`](@extref `Base.SubString`) has its start
point in the `.offset` field, this may be used to inform the user where the missing
close quote belongs.

## Working With Matched Data

[`PegMatch`](@ref) implements the interface of AbstractMatch, and as such, it is
intentionally structured to be similar to [`RegexMatch`](@extref `Base.RegexMatch`)
from the standard library.  PEGs are a far richer and more sophisticated tool than
regexen, however: a named capture might appear many times, captures can be grouped,
those groups may have groups, with captures, having names, and so on.

Our intention is that simple matching will behave in a familiar way, with additional
methods provided for more complex scenarios.  Let's consider a simple rule with some
captures.

```jldoctest baddate
julia> @rule :baddate ← (R"09"^[4], :year) * "-" * (R"09"^[2:2],) * "-" * (R"09"^[2], :day);

julia> date = match(baddate, "2024-01-10")
PegMatch([:year => "2024", "01", :day => "10"])
```

The rule name is because this is certainly not how you should parse a date!  Note the
two equivalent ways of specifying a definite number of repetitions, `[2]` is
preferred.

Let's illustrate how to work with this.

```jldoctest baddate
julia> date == [:year => "2024", "01", :day => "10"]
true

julia> [:year => "2024", "01", :day => "10"] == date
true
```

A [`PegMatch`](@ref) is [`==`](@extref `Base.:==`) to a [`Vector`](@extref
`Base.AbstractVector`) with the same contents.  However, note that a `PegMatch` uses
default hash equality:

```jldoctest baddate
julia> hash(date) == hash([:year => "2024", "01", :day => "10"])
false
```

This is somewhat at variance with [doctrine](@extref `Base.hash`), but we feel it's
the correct choice here.

Next, let's look at iteration and indexing.

```jldoctest baddate
julia> date[:day]
"10"

julia> date[3]
"10"

julia> keys(date)
3-element Vector{Any}:
  :year
 2
  :day

julia> collect(date)
3-element Vector{Any}:
 "2024"
 "01"
 "10"

julia> collect(eachindex(date))
3-element Vector{Int64}:
 1
 2
 3

julia> collect(pairs(date))
3-element Vector{Pair{A, SubString{String}} where A}:
 :year => "2024"
     2 => "01"
  :day => "10"

julia> collect(enumerate(date))
3-element Vector{Pair{Int64, SubString{String}}}:
 1 => "2024"
 2 => "01"
 3 => "10"
```

Default iteration will get you the matches, [`pairs`](@extref `Base.pairs`) uses the
name of the capture when there is one, if a capture has a name, that can be used to
index it, or the position in the Vector.

So far so good, what happens if a named capture matches more than once?

```jldoctest
julia> @rule :abcs ← ((R"az"^1, :abc) | "123")^1;

julia> letters = match(abcs, "abc123def123ghi123")
PegMatch([:abc => "abc", :abc => "def", :abc => "ghi"])

julia> letters[:abc]
"abc"

julia> keys(letters)
3-element Vector{Any}:
  :abc
 2
 3

julia> collect(pairs(letters))
3-element Vector{Pair{Symbol, SubString{String}}}:
 :abc => "abc"
 :abc => "def"
 :abc => "ghi"
```

As you can see, the _first_ match with that name is the indexable one, and therefore,
is the only time `:abc` appears in `keys`, while all matches have their name in
`pairs`, or, if anonymous, their index.
